import streamlit as st
import pandas as pd
import requests
import io
import datetime

# ==========================================
# 1. ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°
# ==========================================
def clean_text(t):
    if not t: return ""
    return str(t).upper().replace("*","X").replace("Ã—","X").replace(" ","").strip()

# ==========================================
# 2. ãƒã‚¹ã‚¿ãƒ¼èª­ã¿è¾¼ã¿
# ==========================================
SHEET_ID = "1vyjK-jW-5Nl0VRHZRUyKlNAqIaO49NUxe3-kwvTtSUg"
SHEET_NAME = "master"
SHEET_URL = f"https://docs.google.com/spreadsheets/d/{SHEET_ID}/gviz/tq?tqx=out:csv&sheet={SHEET_NAME}"

@st.cache_data(ttl=300)
def load_master():
    try:
        response = requests.get(SHEET_URL)
        response.encoding = 'utf-8'
        df = pd.read_csv(io.StringIO(response.text))
        df = df.iloc[:, [0, 1]]
        df.columns = ['ã‚µã‚¤ã‚º', 'å˜é‡']
        df['ã‚µã‚¤ã‚º_KEY'] = df['ã‚µã‚¤ã‚º'].apply(clean_text)
        df['å˜é‡'] = pd.to_numeric(df['å˜é‡'], errors='coerce')
        df = df.drop_duplicates(subset='ã‚µã‚¤ã‚º_KEY')
        return df.dropna(subset=['å˜é‡']).set_index('ã‚µã‚¤ã‚º_KEY')[['ã‚µã‚¤ã‚º', 'å˜é‡']].to_dict('index')
    except Exception:
        return {}

# ==========================================
# 3. ãƒ­ã‚¸ãƒƒã‚¯ï¼šæœ€çŸ­å®šå°ºå„ªå…ˆãƒ»ãƒ­ã‚¹æœ€å°åŒ–
# ==========================================
def calculate_nesting_optimal(required_parts, available_stocks, kerf, min_waste, max_waste):
    remaining_parts = sorted(required_parts, key=lambda x: x['len'], reverse=True)
    results = []
    stocks_asc = sorted(available_stocks)

    while remaining_parts:
        best_fit = None
        for s_len in stocks_asc:
            temp_parts_indices = []
            current_free = s_len
            for i, part in enumerate(remaining_parts):
                needed = part['len'] + (kerf if temp_parts_indices else 0)
                if current_free >= needed:
                    temp_parts_indices.append(i)
                    current_free -= (part['len'] + kerf)
            
            if temp_parts_indices:
                total_parts_len = sum(remaining_parts[i]['len'] for i in temp_parts_indices)
                waste = s_len - total_parts_len - (len(temp_parts_indices)-1)*kerf
                if (min_waste <= waste <= max_waste) or (waste <= kerf):
                    best_fit = {"stock_len": s_len, "indices": temp_parts_indices, "waste": int(waste)}
                    break
        
        if best_fit:
            chosen_parts = [remaining_parts[i] for i in best_fit["indices"]]
            for i in sorted(best_fit["indices"], reverse=True):
                remaining_parts.pop(i)
            results.append({"stock_len": best_fit["stock_len"], "parts": chosen_parts, "waste": best_fit["waste"]})
        else:
            if remaining_parts:
                part = remaining_parts.pop(0)
                max_s = max(available_stocks)
                results.append({"stock_len": max_s, "parts": [part], "waste": int(max_s - part['len'])})
            else: break
    return results

# ==========================================
# 4. ç”»é¢æ§‹æˆ
# ==========================================
st.set_page_config(page_title="é‹¼æä¸€æ‹¬å–ã‚Šåˆã‚ã›ã‚·ã‚¹ãƒ†ãƒ ", layout="wide")
st.title("ğŸ—ï¸ é‹¼æä¸€æ‹¬å–ã‚Šåˆã‚ã›ãƒ»é‡é‡è¨ˆç®—ã‚·ã‚¹ãƒ†ãƒ ")

master_dict = load_master()
size_options = ["(æœªé¸æŠ)"] + [v['ã‚µã‚¤ã‚º'] for v in master_dict.values()]

# --- ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ– ---
if "rows" not in st.session_state:
    st.session_state.rows = 1
if "calc_results" not in st.session_state:
    st.session_state.calc_results = None

# ã€ä¿®æ­£ï¼šæœ€å¼·ã®ãƒªã‚»ãƒƒãƒˆå‡¦ç†ã€‘
def reset_everything():
    # å…¨ã¦ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚­ãƒ¼ã‚’å®Œå…¨ã«å‰Šé™¤
    for key in list(st.session_state.keys()):
        del st.session_state[key]
    # ãƒšãƒ¼ã‚¸ã‚’ãƒªãƒ­ãƒ¼ãƒ‰ï¼ˆã“ã‚Œã§ã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆãŒå®Œå…¨ã«åˆæœŸåŒ–ã•ã‚Œã‚‹ï¼‰
    st.rerun()

with st.sidebar:
    st.header("ğŸ¢ ç‰©ä»¶æƒ…å ±")
    pj_name = st.text_input("ç‰©ä»¶åãƒ»ç¾å ´å", placeholder="ä¾‹ï¼šã€‡ã€‡é‚¸æ–°ç¯‰å·¥äº‹", key="pj_name_input")
    st.divider()
    
    default_kerf = st.number_input("åˆ‡æ–­ã‚·ãƒ­ (mm)", value=5, step=1)
    
    st.write("æ®‹æè¨±å®¹ç¯„å›² (mm)")
    c_w1, c_w2 = st.columns(2)
    with c_w1:
        min_waste = st.number_input("æœ€å°", value=10, step=10)
    with c_w2:
        max_waste = st.number_input("æœ€å¤§", value=1000, step=100)
    
    st.write("ä½¿ç”¨ã™ã‚‹å®šå°ºé•·ã•")
    stock_lengths = sorted([L for L in range(6000, 13000, 1000)])
    selected_stocks = [L for L in stock_lengths if st.checkbox(f"{L}mm", value=True, key=f"stock_{L}")]
    
    st.divider()
    # ãƒœã‚¿ãƒ³ã‚¯ãƒªãƒƒã‚¯ã§ãƒªã‚»ãƒƒãƒˆé–¢æ•°ã‚’å®Ÿè¡Œ
    st.button("ğŸ”´ å…¨ã¦ãƒªã‚»ãƒƒãƒˆ", use_container_width=True, on_click=reset_everything)

st.write("### 1. åˆ‡æ–­ãƒªã‚¹ãƒˆå…¥åŠ›")
input_data_list = []
for i in range(st.session_state.get('rows', 1)):
    with st.container():
        c1, c2 = st.columns([1, 2])
        with c1:
            s_size = st.selectbox(f"ã‚µã‚¤ã‚ºé¸æŠ {i+1}", options=size_options, key=f"size_sel_{i}")
            m_data = master_dict.get(clean_text(s_size), {"ã‚µã‚¤ã‚º": "æœªé¸æŠ", "å˜é‡": 0.0})
            if s_size != "(æœªé¸æŠ)": st.info(f"å˜é‡: {m_data['å˜é‡']} kg/m")
        with c2:
            # keyã‚’å‹•çš„ã«ã™ã‚‹ã“ã¨ã§ãƒªã‚»ãƒƒãƒˆæ™‚ã«ç¢ºå®Ÿã«æ¶ˆå»
            init_df = pd.DataFrame([{"ãƒãƒ¼ã‚¯": "", "é•·ã•(mm)": None, "æœ¬æ•°": None} for _ in range(3)])
            edited_df = st.data_editor(init_df, num_rows="dynamic", key=f"editor_{i}", use_container_width=True)
        
        if s_size != "(æœªé¸æŠ)":
            input_data_list.append({"size_name": m_data['ã‚µã‚¤ã‚º'], "unit_weight": m_data['å˜é‡'], "df": edited_df})
    st.divider()

def add_row():
    st.session_state.rows = st.session_state.get('rows', 1) + 1

st.button("â• é‹¼ç¨®ã‚’å¢—ã‚„ã™", on_click=add_row)

if st.button("ğŸš€ è¨ˆç®—å®Ÿè¡Œ", type="primary"):
    if not selected_stocks:
        st.error("å®šå°ºé•·ã•ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
    else:
        results_data = []
        for data in input_data_list:
            # ç©ºè¡Œã‚’æ’é™¤
            df_valid = data['df'].dropna(subset=["é•·ã•(mm)", "æœ¬æ•°"])
            parts = []
            for _, row in df_valid.iterrows():
                try:
                    l = float(row["é•·ã•(mm)"])
                    n = int(row["æœ¬æ•°"])
                    m = str(row["ãƒãƒ¼ã‚¯"])
                    for _ in range(n):
                        parts.append({"len": l, "mark": m})
                except:
                    continue
            
            if parts:
                res = calculate_nesting_optimal(parts, selected_stocks, default_kerf, min_waste, max_waste)
                results_data.append({"size": data['size_name'], "unit_w": data['unit_weight'], "nesting": res})
        
        st.session_state.calc_results = results_data

# --- çµæœãƒ»å¸³ç¥¨å‡ºåŠ›ï¼ˆã“ã“ã‹ã‚‰ä¸‹ã¯ãƒœã‚¿ãƒ³ã®å¾©å…ƒã‚’ç¶­æŒï¼‰ ---
if st.session_state.get('calc_results'):
    st.write("### 2. è¨ˆç®—çµæœ")
    total_order_rows = []
    inst_rows = []
    grand_total_weight = 0.0
    pdf_html_inst = "<style>@media print { .page-break { page-break-before: always; } } body { font-family: sans-serif; } .item-container { margin-bottom: 40px; border-bottom: 2px solid #000; padding-bottom: 20px; } .bar-outer { display: flex; width: 100%; height: 40px; background: #fff; border: 2px solid #000; margin: 10px 0; } </style>"

    for i, item in enumerate(st.session_state.calc_results):
        pdf_html_inst += f"<div class='item-container {'page-break' if i>0 else ''}'><h2>åˆ‡æ–­åŠ å·¥æŒ‡ç¤ºæ›¸ ({item['size']})</h2><p>ç‰©ä»¶å: {pj_name}</p>"
        with st.expander(f"ğŸ“¦ {item['size']} (å˜é‡: {item['unit_w']} kg/m)", expanded=True):
            for idx, r in enumerate(item['nesting']):
                st.write(f"**No.{idx+1} (å®šå°º:{r['stock_len']}mm)**")
                bar_parts_html = "".join([f'<div style="width: {(p["len"]/r["stock_len"])*100}%; background: #333; border-right: 1px solid #fff;"></div>' for p in r['parts']])
                st.markdown(f'<div style="display: flex; width: 100%; height: 30px; background: #fff; border: 2px solid #000; margin-bottom: 5px;">{bar_parts_html}</div>', unsafe_allow_html=True)
                detail_txt = " / ".join([f"({seq+1}) {p['mark']}:{int(p['len'])}mm" for seq, p in enumerate(r['parts'])])
                st.caption(f"{detail_txt} [ç«¯æ:{int(r['waste'])}mm]")
                pdf_html_inst += f"<div style='margin-top:20px;'><strong>No.{idx+1} | å®šå°º: {r['stock_len']}mm</strong></div><div class='bar-outer'>{bar_parts_html}</div><div style='font-size:14px;'>{detail_txt} [ç«¯æ:{int(r['waste'])}mm]</div>"
                inst_rows.append({"ç‰©ä»¶å": pj_name, "é‹¼ç¨®": item['size'], "No": idx+1, "å®šå°º(mm)": r['stock_len'], "åˆ‡æ–­æ§‹æˆ": detail_txt, "ç«¯æ(mm)": int(r['waste'])})
            
            counts = pd.Series([r['stock_len'] for r in item['nesting']]).value_counts().sort_index()
            summary_data = []
            for s_len, count in counts.items():
                weight = round((s_len / 1000) * item['unit_w'] * count, 2)
                summary_data.append({"å®šå°º(mm)": s_len, "å¿…è¦æœ¬æ•°": count, "é‡é‡åˆè¨ˆ(kg)": weight})
                total_order_rows.append({"ç‰©ä»¶å": pj_name, "é‹¼ç¨®": item['size'], "å®šå°º(mm)": s_len, "æœ¬æ•°": count, "ç·é‡é‡(kg)": weight})
                grand_total_weight += weight
            st.table(pd.DataFrame(summary_data))
        pdf_html_inst += "</div>"

    st.divider()
    st.metric(label="ğŸ å…¨é‹¼ç¨® ç·åˆè¨ˆé‡é‡", value=f"{round(grand_total_weight, 2)} kg")
    st.divider()

    st.write("### 3. å¸³ç¥¨å‡ºåŠ›")
    today = datetime.date.today().strftime("%Y%m%d")
    c1, c2 = st.columns(2)
    with c1:
        st.info("ğŸ“Š **ç™ºæ³¨æ›¸**")
        if total_order_rows:
            st.download_button("ğŸ’¾ CSVã§ä¿å­˜", pd.DataFrame(total_order_rows).to_csv(index=False).encode('utf-8-sig'), f"Order_{today}.csv", "text/csv", key="dl_order_csv")
            order_html = f"<h2>é‹¼æç™ºæ³¨æ›¸</h2><p>ç‰©ä»¶å: {pj_name}</p><table border='1' style='border-collapse:collapse; width:100%;'><tr><th>é‹¼ç¨®</th><th>å®šå°º</th><th>æœ¬æ•°</th><th>é‡é‡(kg)</th></tr>"
            for d in total_order_rows: order_html += f"<tr><td>{d['é‹¼ç¨®']}</td><td>{d['å®šå°º(mm)']}mm</td><td>{d['æœ¬æ•°']}</td><td>{d['ç·é‡é‡(kg)']}</td></tr>"
            order_html += f"<tr><td colspan='3' align='right'><b>ç·åˆè¨ˆé‡é‡</b></td><td><b>{round(grand_total_weight, 2)} kg</b></td></tr></table><script>window.print();</script>"
            st.download_button("ğŸ–¨ï¸ PDF/å°åˆ·ç”¨", order_html, f"Order_{today}.html", "text/html", key="dl_order_html")
    with c2:
        st.info("âœ‚ï¸ **åŠ å·¥æŒ‡ç¤ºæ›¸**")
        if inst_rows:
            st.download_button("ğŸ’¾ CSVã§ä¿å­˜", pd.DataFrame(inst_rows).to_csv(index=False).encode('utf-8-sig'), f"CutList_{today}.csv", "text/csv", key="dl_cut_csv")
            st.download_button("ğŸ–¨ï¸ PDF/å°åˆ·ç”¨", pdf_html_inst + "<script>window.print();</script>", f"CutList_{today}.html", "text/html", key="dl_cut_html")
